{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "from matplotlib import pyplot as plt\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_train = pd.read_csv('train.csv')\n",
      "data_train['SibSp_bin'] = pd.cut(data_train.SibSp, [-np.inf, 0, 1, np.inf], labels=False)\n",
      "data_train['Parch_bin'] = pd.cut(data_train.Parch, [-np.inf, 0, 1, np.inf], labels=False)\n",
      "data_train.groupby('Parch_bin').agg({'Survived': [np.mean, np.size]})\n",
      "data_train.info()\n",
      "\n",
      "data_test = pd.read_csv('test.csv')\n",
      "data_test['SibSp_bin'] = pd.cut(data_test.SibSp, [-np.inf, 0, 1, np.inf], labels=False)\n",
      "data_test['Parch_bin'] = pd.cut(data_test.Parch, [-np.inf, 0, 1, np.inf], labels=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 891 entries, 0 to 890\n",
        "Data columns (total 14 columns):\n",
        "PassengerId    891 non-null int64\n",
        "Survived       891 non-null int64\n",
        "Pclass         891 non-null int64\n",
        "Name           891 non-null object\n",
        "Sex            891 non-null object\n",
        "Age            714 non-null float64\n",
        "SibSp          891 non-null int64\n",
        "Parch          891 non-null int64\n",
        "Ticket         891 non-null object\n",
        "Fare           891 non-null float64\n",
        "Cabin          204 non-null object\n",
        "Embarked       889 non-null object\n",
        "SibSp_bin      891 non-null int64\n",
        "Parch_bin      891 non-null int64\n",
        "dtypes: float64(2), int64(7), object(5)"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# SGD with higher order terms and interactions\n",
      "# with normalization\n",
      "# with imputer\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "from sklearn.preprocessing import PolynomialFeatures, OneHotEncoder, LabelEncoder, MinMaxScaler, StandardScaler\n",
      "from sklearn.preprocessing import Imputer\n",
      "from helpers import MultiLabelEncoder, OneHotEncoderMinusOne, GenericPolyFeatures, GenericImputer\n",
      "\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "from sklearn.pipeline import make_pipeline, Pipeline\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "\n",
      "X_train = data_train[['Pclass', 'SibSp_bin', 'Parch_bin', 'Embarked', 'Sex', 'Fare']].values\n",
      "y_train = data_train['Survived'].values\n",
      "\n",
      "pipeline = make_pipeline(MultiLabelEncoder([0, 3, 4]), \n",
      "                    GenericImputer([5], ['median']),\n",
      "                    OneHotEncoderMinusOne([0, 1, 2, 3, 4]),\n",
      "                    GenericPolyFeatures([-1], degree=2),\n",
      "                    StandardScaler()\n",
      "                    )\n",
      "\n",
      "X_train = pipeline.fit_transform(X_train)\n",
      "\n",
      "\n",
      "param_grid = [{\n",
      "               'alpha': [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1],\n",
      "               'l1_ratio': np.linspace(0.01, 0.99, num=20)\n",
      "             }]\n",
      "clf = GridSearchCV(SGDClassifier(loss='log', penalty='elasticnet'), param_grid, scoring='accuracy', cv=10, n_jobs=1)\n",
      "clf.fit(X_train, y_train)\n",
      "print clf.best_score_\n",
      "print \n",
      "print clf.best_params_\n",
      "print \n",
      "print clf.best_estimator_\n",
      "\n",
      "clf = make_pipeline(pipeline, clf.best_estimator_)\n",
      "print clf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.809203142536\n",
        "\n",
        "{'alpha': 0.01, 'l1_ratio': 0.68052631578947365}\n",
        "\n",
        "SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
        "       eta0=0.0, fit_intercept=True, l1_ratio=0.68052631578947365,\n",
        "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
        "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
        "       verbose=0, warm_start=False)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Pipeline(steps=[('pipeline', Pipeline(steps=[('multilabelencoder', MultiLabelEncoder(cols=[0, 3, 4])), ('genericimputer', GenericImputer(cols=None, methods=None)), ('onehotencoderminusone', OneHotEncoderMinusOne(cols=[0, 1, 2, 3, 4])), ('genericpolyfeatures', GenericPolyFeatures(degree=None, non_dummy_featur...ty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
        "       verbose=0, warm_start=False))])\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_test = data_test[['Pclass', 'SibSp_bin', 'Parch_bin', 'Embarked', 'Sex', 'Fare']].values\n",
      "test1 = pipeline.steps[0][1].fit_transform(X_test)\n",
      "test2 = pipeline.steps[1][1].fit_transform(test1)\n",
      "test3 = pipeline.steps[2][1].fit_transform(test2)\n",
      "# test4 = pipeline.steps[3][1].fit_transform(test3)\n",
      "test2[:, 3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "array([ 1.,  2.,  1.,  2.,  2.,  2.,  1.,  2.,  0.,  2.,  2.,  2.,  2.,\n",
        "        2.,  2.,  0.,  1.,  0.,  2.,  0.,  0.,  2.,  2.,  0.,  0.,  2.,\n",
        "        0.,  0.,  2.,  0.,  2.,  2.,  2.,  2.,  0.,  0.,  2.,  2.,  2.,\n",
        "        2.,  0.,  2.,  2.,  2.,  2.,  2.,  0.,  1.,  0.,  2.,  2.,  0.,\n",
        "        2.,  2.,  0.,  1.,  2.,  2.,  2.,  0.,  2.,  2.,  2.,  1.,  0.,\n",
        "        2.,  1.,  2.,  0.,  2.,  1.,  2.,  2.,  0.,  0.,  0.,  2.,  2.,\n",
        "        2.,  1.,  0.,  2.,  2.,  2.,  1.,  0.,  1.,  2.,  1.,  2.,  2.,\n",
        "        2.,  2.,  2.,  0.,  2.,  2.,  2.,  2.,  2.,  0.,  2.,  1.,  2.,\n",
        "        0.,  2.,  1.,  1.,  2.,  2.,  0.,  1.,  0.,  1.,  2.,  0.,  0.,\n",
        "        2.,  0.,  2.,  2.,  1.,  0.,  2.,  1.,  2.,  2.,  1.,  2.,  2.,\n",
        "        2.,  0.,  2.,  0.,  2.,  2.,  0.,  2.,  2.,  2.,  2.,  2.,  0.,\n",
        "        2.,  2.,  2.,  2.,  2.,  2.,  2.,  0.,  0.,  2.,  2.,  2.,  2.,\n",
        "        2.,  2.,  2.,  2.,  1.,  0.,  2.,  2.,  2.,  2.,  0.,  2.,  0.,\n",
        "        2.,  2.,  0.,  2.,  0.,  2.,  2.,  2.,  0.,  2.,  0.,  2.,  0.,\n",
        "        2.,  1.,  0.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  1.,  2.,\n",
        "        2.,  0.,  2.,  2.,  2.,  1.,  2.,  0.,  2.,  2.,  0.,  1.,  2.,\n",
        "        0.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  1.,  2.,  0.,  2.,  0.,\n",
        "        2.,  2.,  2.,  0.,  0.,  2.,  1.,  2.,  2.,  2.,  2.,  2.,  1.,\n",
        "        0.,  2.,  0.,  0.,  2.,  0.,  0.,  2.,  0.,  2.,  2.,  2.,  2.,\n",
        "        2.,  2.,  0.,  2.,  2.,  0.,  2.,  2.,  2.,  1.,  2.,  2.,  2.,\n",
        "        2.,  2.,  2.,  2.,  0.,  2.,  2.,  2.,  2.,  2.,  0.,  1.,  0.,\n",
        "        1.,  0.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  1.,  0.,  2.,  2.,\n",
        "        2.,  2.,  0.,  2.,  2.,  1.,  0.,  2.,  2.,  2.,  0.,  0.,  2.,\n",
        "        2.,  2.,  0.,  2.,  2.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  0.,\n",
        "        2.,  1.,  0.,  1.,  0.,  2.,  2.,  2.,  2.,  0.,  2.,  2.,  2.,\n",
        "        2.,  2.,  0.,  2.,  2.,  2.,  0.,  0.,  0.,  2.,  2.,  2.,  0.,\n",
        "        2.,  0.,  2.,  2.,  2.,  0.,  2.,  2.,  2.,  0.,  2.,  2.,  0.,\n",
        "        2.,  2.,  2.,  2.,  2.,  2.,  2.,  1.,  2.,  2.,  0.,  2.,  2.,\n",
        "        0.,  2.,  0.,  2.,  0.,  0.,  2.,  0.,  2.,  2.,  2.,  0.,  2.,\n",
        "        2.,  2.,  2.,  1.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  1.,  2.,\n",
        "        2.,  2.,  2.,  2.,  2.,  2.,  1.,  0.,  2.,  1.,  2.,  2.,  0.,\n",
        "        2.,  0.,  0.,  2.,  0.,  1.,  2.,  1.,  1.,  2.,  2.,  0.,  2.,\n",
        "        2.,  0.], dtype=float32)"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "oh = OneHotEncoder(sparse=False)\n",
      "le = LabelEncoder()\n",
      "le.fit(data_train['Embarked'].values)\n",
      "le.transform(data_test['Embarked'].values)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "array([2, 3, 2, 3, 3, 3, 2, 3, 1, 3, 3, 3, 3, 3, 3, 1, 2, 1, 3, 1, 1, 3, 3,\n",
        "       1, 1, 3, 1, 1, 3, 1, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3,\n",
        "       1, 2, 1, 3, 3, 1, 3, 3, 1, 2, 3, 3, 3, 1, 3, 3, 3, 2, 1, 3, 2, 3, 1,\n",
        "       3, 2, 3, 3, 1, 1, 1, 3, 3, 3, 2, 1, 3, 3, 3, 2, 1, 2, 3, 2, 3, 3, 3,\n",
        "       3, 3, 1, 3, 3, 3, 3, 3, 1, 3, 2, 3, 1, 3, 2, 2, 3, 3, 1, 2, 1, 2, 3,\n",
        "       1, 1, 3, 1, 3, 3, 2, 1, 3, 2, 3, 3, 2, 3, 3, 3, 1, 3, 1, 3, 3, 1, 3,\n",
        "       3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 2,\n",
        "       1, 3, 3, 3, 3, 1, 3, 1, 3, 3, 1, 3, 1, 3, 3, 3, 1, 3, 1, 3, 1, 3, 2,\n",
        "       1, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 1, 3, 3, 3, 2, 3, 1, 3, 3, 1, 2,\n",
        "       3, 1, 3, 3, 3, 3, 3, 3, 3, 2, 3, 1, 3, 1, 3, 3, 3, 1, 1, 3, 2, 3, 3,\n",
        "       3, 3, 3, 2, 1, 3, 1, 1, 3, 1, 1, 3, 1, 3, 3, 3, 3, 3, 3, 1, 3, 3, 1,\n",
        "       3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 1, 2, 1, 2, 1, 3,\n",
        "       3, 3, 3, 3, 3, 3, 2, 1, 3, 3, 3, 3, 1, 3, 3, 2, 1, 3, 3, 3, 1, 1, 3,\n",
        "       3, 3, 1, 3, 3, 2, 3, 3, 3, 3, 3, 3, 1, 3, 2, 1, 2, 1, 3, 3, 3, 3, 1,\n",
        "       3, 3, 3, 3, 3, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3, 1, 3, 1, 3, 3, 3, 1, 3,\n",
        "       3, 3, 1, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 1, 3, 3, 1, 3, 1, 3,\n",
        "       1, 1, 3, 1, 3, 3, 3, 1, 3, 3, 3, 3, 2, 2, 3, 3, 3, 3, 3, 3, 2, 3, 3,\n",
        "       3, 3, 3, 3, 3, 2, 1, 3, 2, 3, 3, 1, 3, 1, 1, 3, 1, 2, 3, 2, 2, 3, 3,\n",
        "       1, 3, 3, 1])"
       ]
      }
     ],
     "prompt_number": 41
    }
   ],
   "metadata": {}
  }
 ]
}